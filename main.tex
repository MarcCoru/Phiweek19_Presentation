\documentclass[%
  aspectratio=169,
  9pt,
%   t,
  %USenglish,
  english,
%   dark,
  light,
  mathserif,
%   serif, 
  professionalfont,
%  handout,
%  affiliationinhead,
  affiliationintitlepagehead,
  titlegraphic,
  %% The following options would violate the CD rules!
   affiliation,
%   uselogos,
  % navigationbar,
  %progressbar,
%   seprules,
%   titleinhead,
]{beamer}

%
%\usepackage{tikz}
%\usepackage{pgfplots}
%\usepgfplotslibrary{groupplots}

\input{preamble.tex}
\usetheme{TUM}

\input{images/rawinput.tikz}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Convolutional-Recurrent Networks for Multi-temporal Classification
\title{Cloud-Robust Classification of Remote Sensing Time Series}
%\subtitle{NeurIPS 2018 Workshop on Spatiotemporal Modeling and Decision-making}
\subtitle{$\Phi$-week 2019}
\author[M. Rußwurm, M. Körner]{Marc Rußwurm, Marco Körner}
\institute[TUM]{%
	%	Technical University of Munich\\Chair of Remote Sensing Technology\\Computer Vision Research Group\\\url{www.lmf.bgu.tum.de/vision}
}

\date{13th September 2019, ESA ESRIN, Frascati, Italy}


\input{bubbles.tex}
\begin{document}

\begin{frame}[t]
  \titlepage
\end{frame}

%\begin{frame}
%	\frametitle{Outline}
%	
%	First, introduce
%	\begin{description}
%		\item time series data and
%		\item the application   identification 
%		\item address data pre-processing
%		\item and end-to-end learning of deep neural networks
%	\end{description}
%
%	Then, qualitatively demonstrate the mechanisms of
%	\begin{description}
%		\item Gated Recurrence 
%		\item Self-attention
%	\end{description}
%
%	Finally, show quantitative results on 
%	\begin{description}
%		\item preprocessed and
%		\item raw Sentinel 2 Time Series
%	\end{description}
%\end{frame}

\input{sections/intro.tex}	

\begin{frame}<presentation:1-6>
\frametitle{Data Preprocessing}
%	
%	[format] in this presentation we have the special opportunity to to compare commercially pre-processed satellite imagery with raw imagery on crop type classification in Bavaria Germany.
%	
\begin{tikzpicture}[node distance=.1em]
\node[draw=black, rounded corners, minimum height=3cm, minimum width=4.5cm, label=below:preprocessing, font=\Large\bfseries](gaf){%
	\only<1>{\includegraphics[width=2cm]{images/icons/gears}}%
	\only<2>{$f_{\Mweight_\text{sel}}$}%
	\only<3>{$f_{\Mweight_\text{sel}}\left(f_{\Mweight_\text{atm}}\right)$}%
	\only<4>{$f_{\Mweight_\text{sel}}\left(f_{\Mweight_\text{atm}}\left(f_{\Mweight_\text{cl}}\right)\right)$}%
	\only<5>{$f_{\Mweight_\text{sel}}\left(f_{\Mweight_\text{atm}}\left(f_{\Mweight_\text{cl}}\left(f_{\text{int}}\right)\right)\right)$}%
	\only<6>{$\Mweight_\text{preprocessing}$}%
	\only<7>{\includegraphics[width=2cm]{images/GAF_logo}}%
};
\node[right=1.5em of gaf, inner sep=0](raw){\rawtimeseriestwo{12-71456800_raw.csv}};
\node[font=\huge,left=0em of raw, inner sep=0](bopen){$\Bigg($};
\node[font=\huge,right=0em of raw, inner sep=0](bopen){$\Bigg)$};
\visible<1->{
	\node[right=2em of raw, font=\huge](equals){$=$};
	\node[right=of equals, yshift=-1em]{\rawtimeseriestwo{12-71456800.csv}};
}
\end{tikzpicture}

\only<1-6>{
	\begin{rdescription}
		\item[$f_{\Mweight_\text{sel}}(\M{X})$]<2-> temporal selection (not considering winter period) where $\Mweight_\text{sel} = \{t_\text{start}, t_\text{end}\}$
		\item[$f_{\Mweight_\text{atm}}(\M{X})$]<3-> atmospheric correction ($\M{X}_\text{top-of-atmosphere} \rightarrow \M{X}_\text{bottom-of-atmosphere}$)
		\item[$f_{\Mweight_\text{cl}}(\M{X})$]<4-> cloud/cloudshadow classification (F-Mask, MAJA, CNNs, Cloud Clustering (go FDL!))
		\item[$f_{\text{int}}(\M{X})$]<5-> temporal interpolation to generate equal sample times
		\item[$f_{\Mweight_\text{\dots}}$]<6-> \textbf{many more problem specific chained building blocks}	
	\end{rdescription}
}
\only<7>{
	\vspace{2em}
	\centering\Large In this case: Preprocessing Engine of \includegraphics[width=4em]{images/GAF_logo}
}

\end{frame}

\input{sections/neuralnetworks.tex}


%\begin{frame}
%\frametitle{Outline}
%
%\Large
%
%\begin{description}
%	\item[1] A quantitativ comparison \textbf{raw versus preprocessed data} on crop classification
%	\item[2] A \textbf{feature importance analysis} with \textbf{gradients} from a pre-trained RNN Model
%	\item[3] A dive into \textbf{Self-Attention} with qualitative results from raw Sentinel 2 time Series
%\end{description}
%
%\end{frame}%

\input{sections/results.tex}


%\begin{frame}
%\frametitle{Understand Neural Networks}
%\framesubtitle{with three Analyses}
%
%\centering\begin{tikzpicture}
%\node[minimum width=1cm, minimum height=1.5cm, draw,rounded corners](veg) at (0,0){\vegetationsmodell};
%\node[below left=of veg]{Gradient Backprop to X};
%\node[below=of veg]{Gated Recurrence};
%\node[below right=of veg]{Self-Attention};
%\end{tikzpicture}
%
%\end{frame}

\input{sections/attention.tex}
%\input{sections/pool.tex}

{
\setbeamercovered{invisible} 


{\setbeamercolor{background canvas}{bg=tumbluedark}
	\begin{frame}[plain]
	
	\vspace{8em}
	\begin{center}
		\Huge\color{white}
		Let's summarize...
	\end{center}\color{white}
	
\end{frame}
}

\begin{frame}
\frametitle{Summary}
\Large 

\begin{leftbubbles}
	What did we look at?
\end{leftbubbles}

\pause
\begin{rightbubbles}
	end-to-end learning in combination with preprocessing
\end{rightbubbles}

\pause
\begin{rightbubbles}
	quantitative results on models with raw and preprocessed data
\end{rightbubbles}

\pause
\begin{rightbubbles}
	a qualitative example on the self-attention mechanism
\end{rightbubbles}

\end{frame}

\begin{frame}
\frametitle{Conclusion}
\Large 

\begin{leftbubbles}
	What were the results of these experiments?
\end{leftbubbles}

\pause
\begin{rightbubbles}
	end-to-end trained models were robust to noise in the data
\end{rightbubbles}

\pause
\begin{rightbubbles}
	this questions the need of extensive preprocessing for deep learning models
\end{rightbubbles}

\end{frame}
\frametitle{Conclusion}

\begin{frame}
	\Large
	
	\begin{leftbubbles}
		How do deep learning models get robust to noise (aka clouds)?
	\end{leftbubbles}
	
	\pause
	\begin{rightbubbles}
		we saw how self-attention is used to focus on cloud-free observations
	\end{rightbubbles}
	
	\begin{rightbubbles}
		gates in recurrent neural networks work similar {\small (see previous work)}
	\end{rightbubbles}
	

\end{frame}

\begin{frame}
\Large

\begin{leftbubbles}
	Can I play around with the qualitative experiments?
\end{leftbubbles}

\pause
\begin{rightbubbles}
	yes, check out \textbf{github.com/marccoru/phiweek19}
\end{rightbubbles}

\pause
\begin{rightbubbles}
	specifically \textbf{Transformer.ipynb}
\end{rightbubbles}

\pause
\begin{rightbubbles}
	and \textbf{Recurrence.ipynb} {\small (that didn't make the cut for this presentation)}
\end{rightbubbles}


\end{frame}


}	
%\begin{frame}
%\frametitle{Summary}
%
%\pause
%\begin{leftbubbles}
%	what was this presentation about?
%\end{leftbubbles}
%
%\pause
%\begin{rightbubbles}
%	raw data versus preprocessed data when doing end-to-end learning
%\end{rightbubbles}
%
%
%\pause
%\begin{leftbubbles}
%	what was end-to-end learning again?
%\end{leftbubbles}
%
%\pause
%\begin{rightbubbles}
%	it's about learning a model solely from provided input and label data
%	
%	without any region or problem-specific expert knowledge
%\end{rightbubbles}
%
%\end{frame}

%\begin{frame}
%
%	\begin{leftbubbles}
%		what is the difference to common preprocessing pipelines?
%	\end{leftbubbles}
%	
%	\pause
%	\begin{rightbubbles}
%		they are designed specifically for each problem/region.
%	\end{rightbubbles}
%	
%	\pause
%	\begin{rightbubbles}
%		preprocessing may also discard some information \small(NDVI, EVI calculation or temporal interpolation)
%	\end{rightbubbles}
%	
%	\pause
%	\begin{rightbubbles}
%		the parameters are hand chosen based on best practices
%	\end{rightbubbles}
%	
%	\pause
%	\begin{rightbubbles}
%		there is no guarantee that the parameters are optimal for the specific task
%	\end{rightbubbles}
%
%\end{frame}





\begin{frame}
	\frametitle{Thank you}
	
	{\Large\centering 
		\textbf{Marc Rußwurm \& Marco Körner} \\
	
		TUM Chair of Remote Sensing Technology \\
		
		\centering Computer Vision Research Group \\
	}
	
	\vspace{2em}
	\Large 
	\begin{columns}[t]
		\column{.5\textwidth}
		Checkout the TUM Chair: \textbf{www.bgu.tum.de/en/lmf/vision/}
		\vspace{1em}
		
		our official \includegraphics[width=5mm]{images/github} account: \textbf{http://github.com/tum-lmf}
		\vspace{1em}
		
		data cooperation for this work with \includegraphics[height=1em]{images/GAF_logo}
		
		\column{.5\textwidth}
		clone the repo to the experiments! 
		{\textbf{github.com/marccoru/phiweek19}}
		
		\vspace{1em}
		\includegraphics[height=5mm]{images/twitter} follow \textbf{@marccoru} for updates.
		
		\vspace{1em}
		\includegraphics[height=5mm]{images/github} \textbf{github.com/marccoru} for code.
		
	\end{columns}

	
	
\end{frame}

\input{sections/gradients.tex}
\input{sections/recurrence.tex}



\end{document}


